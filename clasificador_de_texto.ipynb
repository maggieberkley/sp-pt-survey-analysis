{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PPMl5u3VIZTE"
      },
      "source": [
        "# **CLASIFICADOR DE TEXTO**\n",
        "En este Colab entrené varios modelos para clasificar las respuestas a las encuestas.\n",
        "\n",
        "Los datos de entrenamiento son las respuestas a las encuestas anteriores etiquetadas con tres categorías: producto, servicio y general. Agregué algunas respuestas generadas por ChatGPT para aumentar la cantidad de datos en las categorías de servicio y general. Aún así, la mayoría de las respuestas tienen la categoría de producto.\n",
        "\n",
        "Usando los datos de entrenamiento, ajusté el modelo de lenguaje previamente entrenado con textos españoles [BETO](https://github.com/dccuchile/beto).\n",
        "\n",
        "Para entrenar el modelo, usé como referencia [estas instrucciones de HuggingFace](https://huggingface.co/docs/transformers/tasks/sequence_classification) y [este Colab](https://github.com/CSCI-3349-F22/lab8/tree/main)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZqU1a2nyPoU"
      },
      "source": [
        "## Parte 1: Autorización e instalación de bibliotecas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Primero que nada, cambiá el runtime type a GPU. Esto hace que ande mucho más rápido el programa.\n",
        "# Runtime –> Change runtime type –> T4 GPU\n",
        "\n",
        "# Google Colab pone límites a la cantidad de uso que le podés dar a la GPU.\n",
        "# Si alcanzás el límite, podés usar la CPU. Normalmente, el límite se elimina dentro de dos o tres días."
      ],
      "metadata": {
        "id": "AsWdDa_8wrG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZm_ZvQv4RTF"
      },
      "outputs": [],
      "source": [
        "# Monta tu unidad de Google Drive.\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EBL_-voQ-TMS"
      },
      "outputs": [],
      "source": [
        "# Autentica al usuario en Google Colab y configura las credenciales para acceder a Google Sheets.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "import gspread\n",
        "from google.auth import default\n",
        "creds, _ = default()\n",
        "gc = gspread.authorize(creds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGSLG_nRMmyV"
      },
      "outputs": [],
      "source": [
        "# Instala las librerías necesarias.\n",
        "# Este paso puede tardar un poco.\n",
        "!pip install transformers datasets torch scikit-learn accelerate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UBMALgIUydAd"
      },
      "source": [
        "## Parte 2: Preparación y tokenización"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G-V7vUFv-EvA"
      },
      "outputs": [],
      "source": [
        "# Abre y lee el Sheet que tiene los datos de entrenamiento.\n",
        "# Este Sheet tiene dos columnas: \"respuestas\" y \"categorías\".\n",
        "f = gc.open(\"datos_de_entrenamiento\").sheet1\n",
        "all = f.get_all_values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K-BOKtZ9FXkd"
      },
      "outputs": [],
      "source": [
        "# Ahora tenemos una lista de listas.\n",
        "# Cada lista interna es una fila del Sheet con el formato [respuesta, categoría].\n",
        "\n",
        "# Imprime la lista y la cantidad de elementos.\n",
        "print(all)\n",
        "print(len(all))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NG2ml8f-upt"
      },
      "outputs": [],
      "source": [
        "# Inicializa un diccionario para mapear etiquetas a IDs.\n",
        "label2id = {}\n",
        "# Y uno más para mapear IDs a etiquetas.\n",
        "id2label = {}\n",
        "\n",
        "class_id = 0\n",
        "\n",
        "# Recorre todas las filas.\n",
        "for row in all[1:]:\n",
        "  # Si la etiqueta no está en el diccionario, agrega un nuevo elemento.\n",
        "  if row[1] not in label2id:\n",
        "    label2id[row[1]] = class_id\n",
        "    id2label[class_id] = row[1]\n",
        "    class_id += 1\n",
        "\n",
        "# Recorre todas las filas.\n",
        "for row in all[1:]:\n",
        "  # Reemplaza la etiqueta con su ID correspondiente.\n",
        "  row[1] = label2id[row[1]]\n",
        "\n",
        "# Renombra las columnas (este paso es necesario para el proceso de entrenamiento).\n",
        "all[0][0] = \"text\"\n",
        "all[0][1] = \"label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pB2sP37i4NL4"
      },
      "outputs": [],
      "source": [
        "# Imprime los diccionarios y la lista.\n",
        "print(label2id)\n",
        "print(id2label)\n",
        "\n",
        "print(all)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DkIZZeWpEaj1"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Convierte la lista en un objeto tipo DataFrame.\n",
        "df = pd.DataFrame(all[1:], columns=all[0])\n",
        "\n",
        "# Muestra los primeros datos.\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uao1dedJ9Dpt"
      },
      "outputs": [],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "# Convierte el Dataframe en un objeto tipo Dataset.\n",
        "dataset = Dataset.from_pandas(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7APXhzo1M5w-"
      },
      "outputs": [],
      "source": [
        "# TOKENIZACIÓN\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Carga el tokenizador pre-entrenado de BETO.\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\")\n",
        "\n",
        "# Tokeniza las respuestas.\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
        "\n",
        "tokenized_dataset = dataset.map(tokenize_function, batched=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1gfHsTUCE1q6"
      },
      "source": [
        "## Parte 3: Entrenamiento y evaluación"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "wTti9IbY9DJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MEWJgJA4jt6S"
      },
      "outputs": [],
      "source": [
        "# STRATIFIED SPLIT\n",
        "\n",
        "# Convierte el Dataset tokenizado en un Dataframe.\n",
        "#df_tokenized = pd.DataFrame(tokenized_dataset)\n",
        "\n",
        "# Divide el Dataframe en datos de entrenamiento y datos de prueba.\n",
        "#train_df, test_df = train_test_split(\n",
        "#   df_tokenized,\n",
        "#   test_size=0.2,\n",
        "#   stratify=df['label'],\n",
        "#   random_state=42\n",
        "#)\n",
        "\n",
        "# Convierte los Dataframes en Datasets.\n",
        "#train_dataset = Dataset.from_pandas(train_df)\n",
        "#test_dataset = Dataset.from_pandas(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AS_DApOCjTkO"
      },
      "outputs": [],
      "source": [
        "# NORMAL SPLIT\n",
        "\n",
        "# Divide el Dataset en datos de entrenamiento y datos de prueba.\n",
        "train_test_split = tokenized_dataset.train_test_split(test_size=0.2)\n",
        "train_dataset = train_test_split['train']\n",
        "test_dataset = train_test_split['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qr5CYLHclTun"
      },
      "outputs": [],
      "source": [
        "import accelerate\n",
        "\n",
        "# Carga el clasificador pre-entrenado de BETO.\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"dccuchile/bert-base-spanish-wwm-uncased\", num_labels=len(label2id))\n",
        "\n",
        "# Define los argumentos de entrenamiento.\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/drive/MyDrive/results2\",\n",
        "    eval_strategy=\"epoch\",\n",
        "    logging_dir=\"/content/drive/MyDrive/logs2\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=4,\n",
        "    per_device_eval_batch_size=4,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=100,\n",
        "    save_steps=500,\n",
        "    weight_decay=0.01,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qJWEJ2VxjLTW"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from datasets import load_metric\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "# Define la función de evaluación.\n",
        "def compute_metrics(eval_pred):\n",
        "   load_accuracy = load_metric(\"accuracy\")\n",
        "   load_f1 = load_metric(\"f1\")\n",
        "   logits, labels = eval_pred\n",
        "   predictions = np.argmax(logits, axis=-1)\n",
        "   accuracy = load_accuracy.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "   f1 = f1_score(labels, predictions, average='weighted')\n",
        "   return {\"accuracy\": accuracy, \"f1\": f1}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KhYNm7gtjfeE"
      },
      "outputs": [],
      "source": [
        "# Define el entrenador.\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZvF82M7pAdc"
      },
      "outputs": [],
      "source": [
        "# ENTRENAMIENTO\n",
        "\n",
        "# Entrena el modelo.\n",
        "# Puede que aparezca un aviso que te pregunte si querés ejecutar código externo. Poné \"y\" para continuar.\n",
        "\n",
        "# Este paso puede tardar mucho tiempo si usás la CPU (más de una hora),\n",
        "# pero va más rápido si usás la GPU (menos de 10 minutos, dependiendo de la cantidad de datos).\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rwJsFvLjf37-"
      },
      "outputs": [],
      "source": [
        "# EVALUACIÓN\n",
        "\n",
        "# Evalúa el modelo.\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nYUEocanM6_x"
      },
      "outputs": [],
      "source": [
        "# Guarda el modelo para usarlo en otro Colab.\n",
        "# Antes de guardar un nuevo modelo, asegurate de cambiar el nombre acá para no perder el modelo anterior.\n",
        "trainer.save_model(\"/content/drive/MyDrive/clasificador\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNU0X3xYVp7B"
      },
      "outputs": [],
      "source": [
        "# Guarda el tokenizador para usarlo en otro Colab.\n",
        "# Antes de guardar un nuevo tokenizador, asegurate de cambiar el nombre acá para no perder el tokenizador anterior.\n",
        "tokenizer.save_pretrained(\"/content/drive/MyDrive/clasificador\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfYvoJMtE-SE"
      },
      "source": [
        "## Parte 4: Métricas de entrenamiento y análisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60LuZANG0RFc"
      },
      "source": [
        "\n",
        "**Intento #1**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 3\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Normal split\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.829000\t0.495714\t0.800000\t0.800899\n",
        "2\t0.402700\t0.604519\t0.823077\t0.826417\n",
        "3\t0.265800\t0.796109\t0.846154\t0.839683\n",
        "4\t0.067700\t0.624356\t0.853846\t0.853792\n",
        "```\n",
        "```\n",
        "{'eval_loss': 0.6243564486503601,\n",
        " 'eval_accuracy': 0.8538461538461538,\n",
        " 'eval_f1': 0.8537923614846691,\n",
        " 'eval_runtime': 6.1408,\n",
        " 'eval_samples_per_second': 21.17,\n",
        " 'eval_steps_per_second': 5.374,\n",
        " 'epoch': 4.0}\n",
        "```\n",
        "\n",
        "**Intento #2**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 3\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Stratified split\n",
        "\n",
        "Sin datos generados por ChatGPT\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.636400\t0.807438\t0.783784\t0.748369\n",
        "2\t0.364600\t0.596321\t0.819820\t0.806448\n",
        "3\t0.174100\t0.661458\t0.810811\t0.794967\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.6614578366279602,\n",
        " 'eval_accuracy': 0.8108108108108109,\n",
        " 'eval_f1': 0.7949673811742778,\n",
        " 'eval_runtime': 3.7887,\n",
        " 'eval_samples_per_second': 29.297,\n",
        " 'eval_steps_per_second': 7.39,\n",
        " 'epoch': 3.0}\n",
        "```\n",
        "**Intento #3**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 3\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Normal split\n",
        "\n",
        "Sin datos generados por ChatGPT\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.651000\t0.423073\t0.864865\t0.840319\n",
        "2\t0.364200\t0.480779\t0.864865\t0.865934\n",
        "3\t0.185200\t0.571108\t0.864865\t0.871241\n",
        "```\n",
        "```\n",
        "{'eval_loss': 0.571107804775238,\n",
        " 'eval_accuracy': 0.8648648648648649,\n",
        " 'eval_f1': 0.8712413712413712,\n",
        " 'eval_runtime': 4.2237,\n",
        " 'eval_samples_per_second': 26.28,\n",
        " 'eval_steps_per_second': 6.629,\n",
        " 'epoch': 3.0}\n",
        "```\n",
        "\n",
        "**Intento #4**\n",
        "model_sinprecio2 (me parece que este es el mejor)\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 3\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Stratified split\n",
        "\n",
        "Sin datos de la categoría de \"precio\"\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.760400\t0.485295\t0.779412\t0.777759\n",
        "2\t0.484600\t0.483265\t0.875000\t0.874873\n",
        "3\t0.132500\t0.575767\t0.867647\t0.867629\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.5757667422294617,\n",
        " 'eval_accuracy': 0.8676470588235294,\n",
        " 'eval_f1': 0.8676288133119252,\n",
        " 'eval_runtime': 4.5986,\n",
        " 'eval_samples_per_second': 29.574,\n",
        " 'eval_steps_per_second': 7.394,\n",
        " 'epoch': 3.0}\n",
        "```\n",
        "\n",
        "**Intento #5**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 3\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Normal split\n",
        "\n",
        "Más datos generados por ChatGPT\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.771300\t0.529133\t0.798561\t0.776343\n",
        "2\t0.399200\t0.632740\t0.820144\t0.805573\n",
        "3\t0.157600\t0.484480\t0.848921\t0.837652\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.4844798445701599,\n",
        " 'eval_accuracy': 0.8489208633093526,\n",
        " 'eval_f1': 0.8376516645303023,\n",
        " 'eval_runtime': 4.8769,\n",
        " 'eval_samples_per_second': 28.502,\n",
        " 'eval_steps_per_second': 7.177,\n",
        " 'epoch': 3.0}\n",
        "```\n",
        "\n",
        "**Intento #6**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 4\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Normal split\n",
        "\n",
        "Más datos generados por ChatGPT\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.730800\t0.696785\t0.805755\t0.800822\n",
        "2\t0.467300\t0.545005\t0.863309\t0.861921\n",
        "3\t0.204200\t0.621633\t0.856115\t0.854983\n",
        "4\t0.070200\t0.662710\t0.863309\t0.861774\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.6627101898193359,\n",
        " 'eval_accuracy': 0.8633093525179856,\n",
        " 'eval_f1': 0.86177382204908,\n",
        " 'eval_runtime': 4.9749,\n",
        " 'eval_samples_per_second': 27.94,\n",
        " 'eval_steps_per_second': 7.035,\n",
        " 'epoch': 4.0}\n",
        "```\n",
        "\n",
        "**Intento #7**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 4\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Stratified split\n",
        "\n",
        "```\n",
        "\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.755100\t0.494268\t0.798561\t0.790414\n",
        "2\t0.445800\t0.662144\t0.856115\t0.853485\n",
        "3\t0.111500\t0.828094\t0.827338\t0.825752\n",
        "4\t0.037800\t0.907003\t0.827338\t0.826516\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.907002866268158,\n",
        " 'eval_accuracy': 0.8273381294964028,\n",
        " 'eval_f1': 0.8265160047379337,\n",
        " 'eval_runtime': 5.746,\n",
        " 'eval_samples_per_second': 24.191,\n",
        " 'eval_steps_per_second': 6.091,\n",
        " 'epoch': 4.0}\n",
        "```\n",
        "\n",
        "**Intento #8**\n",
        "\n",
        "Learning rate: 2e-5\n",
        "\n",
        "Batch size: 4\n",
        "\n",
        "Num epochs: 2\n",
        "\n",
        "Weight decay: 0.01\n",
        "\n",
        "Stratified split\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.768700\t0.466155\t0.820144\t0.816058\n",
        "2\t0.447300\t0.491136\t0.848921\t0.845716\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.49113568663597107,\n",
        " 'eval_accuracy': 0.8489208633093526,\n",
        " 'eval_f1': 0.8457159464424776,\n",
        " 'eval_runtime': 5.515,\n",
        " 'eval_samples_per_second': 25.204,\n",
        " 'eval_steps_per_second': 6.346,\n",
        " 'epoch': 2.0}\n",
        "```\n",
        "\n",
        "**Intento #9**\n",
        "\n",
        "Igual que el Intento #5\n",
        "\n",
        "```\n",
        "Epoch\tTraining Loss\tValidation Loss\tAccuracy\tF1\n",
        "1\t0.780700\t0.562730\t0.791367\t0.790950\n",
        "2\t0.475300\t0.659334\t0.812950\t0.811216\n",
        "3\t0.196800\t0.659759\t0.856115\t0.853592\n",
        "```\n",
        "\n",
        "```\n",
        "{'eval_loss': 0.6597588062286377,\n",
        " 'eval_accuracy': 0.8561151079136691,\n",
        " 'eval_f1': 0.8535918613387037,\n",
        " 'eval_runtime': 5.5798,\n",
        " 'eval_samples_per_second': 24.911,\n",
        " 'eval_steps_per_second': 6.273,\n",
        " 'epoch': 3.0}\n",
        "```\n",
        "*Un training loss bajo y un validation loss alto pueden indicar sobreajuste (overfitting)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}